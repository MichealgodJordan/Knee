{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mylosses import SupConLoss as suploss\n",
    "from resnet_big import SupConResNet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "from torch import randperm\n",
    "from util import TwoCropTransform\n",
    "from my_supcon import CustomSubset\n",
    "\n",
    "def set_loader():\n",
    "    # construct data loader\n",
    "    torch.manual_seed(42)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(42)\n",
    "\n",
    "    normalize = transforms.Normalize(mean=[0.5,0.5,0.5], std=[0.5,0.5,0.5])\n",
    "\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize([32,32]),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomApply([\n",
    "            transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)\n",
    "        ], p=0.8),\n",
    "        transforms.RandomGrayscale(p=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    "\n",
    "    img_dataset = datasets.ImageFolder(r'D:\\research\\su\\data\\Knee\\Digital_Knee_X-ray_Images\\MedicalExpert-I')\n",
    "    class_names = img_dataset.classes\n",
    "    size = len(img_dataset)\n",
    "    img_dataset = torch.utils.data.Subset(img_dataset, randperm(size).tolist())\n",
    "    train_indices = range(0, int(size*0.5))\n",
    "    train_set = CustomSubset(img_dataset, train_indices, TwoCropTransform(train_transform))\n",
    "    print(f'train dataset size : {len(train_set)}')\n",
    "    print(f'classes names : {class_names}')\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=10,\n",
    "                                                shuffle=True, pin_memory=True,num_workers=0)\n",
    "    return train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset size : 825\n",
      "classes names : ['0Normal', '1Doubtful', '2Mild', '3Moderate', '4Severe']\n"
     ]
    }
   ],
   "source": [
    "loader = set_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SupConResNet(name='resnet18')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(loader, model, loss):\n",
    "    for images, labels in loader:\n",
    "        print('image list size:', len(images))\n",
    "        images = torch.cat([images[0], images[1]], dim=0)\n",
    "        print('input images size:', images.shape)\n",
    "        bsz = labels.shape[0]\n",
    "        print('bsz:',bsz)\n",
    "        features = model(images)\n",
    "        print('output features shape:', features.shape)\n",
    "        f1, f2 = torch.split(features, [bsz, bsz], dim=0)\n",
    "        print(f'f1 shape:{f1.shape}, f2 shape:{f2.shape}')\n",
    "        features = torch.cat([f1.unsqueeze(1), f2.unsqueeze(1)], dim=1)\n",
    "        print('concatted feature shape:', features.shape)\n",
    "        score = loss(features, labels)\n",
    "        print('loss:', score)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def L2(X,Y):\n",
    "    square_sum_X = torch.sum(X ** 2, dim=1, keepdim=True)\n",
    "    square_sum_Y = torch.sum(Y ** 2, dim=0, keepdim=True)\n",
    "    distances = square_sum_X + square_sum_Y - 2.0 * torch.matmul(X, Y)\n",
    "    distances = torch.sqrt(torch.clamp(distances, min=0.0))\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image list size: 2\n",
      "input images size: torch.Size([20, 3, 32, 32])\n",
      "bsz: 10\n",
      "output features shape: torch.Size([20, 128])\n",
      "f1 shape:torch.Size([10, 128]), f2 shape:torch.Size([10, 128])\n",
      "concatted feature shape: torch.Size([10, 2, 128])\n",
      "loss: tensor(3.3806, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from mylosses import SupConLoss as myloss\n",
    "loss = myloss(dis_func = L2)\n",
    "test(loader, model, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from main_linear import train,set_model,set_optimizer,set_loader\n",
    "# train(loader,model,)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
